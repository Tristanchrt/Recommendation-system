{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project CHRETIEN Tristan |Â DURAND Victor\n",
    "\n",
    "## Installation\n",
    "\n",
    "- Install kaggle using pip3 `pip3 install -r requirements.txt`\n",
    "- Connect to https://kaggle.com \n",
    "- Create an account \n",
    "- Generate API Keys on your account tab\n",
    "- Download kaggle.json file and store it under /home/${USER}/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/user/.kaggle/kaggle.json'\n"
     ]
    }
   ],
   "source": [
    "# Download dataset on kaggle\n",
    "import kaggle\n",
    "\n",
    "kaggle.api.authenticate()\n",
    "# assign directory\n",
    "directory=\"./\"\n",
    "kaggle.api.dataset_download_files('vishalsubbiah/pokemon-images-and-types', path=directory, unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate files metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_image_to_extract = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 50>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m closest_name_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     57\u001b[0m name \u001b[38;5;241m=\u001b[39m metadata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 58\u001b[0m main_colors_value \u001b[38;5;241m=\u001b[39m \u001b[43mmain_colors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(main_colors_value)):\n\u001b[1;32m     60\u001b[0m     rgb_color \u001b[38;5;241m=\u001b[39m ImageColor\u001b[38;5;241m.\u001b[39mgetcolor(main_colors_value[i], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mmain_colors\u001b[0;34m(imgfile)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(numarray\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m     18\u001b[0m     clusters \u001b[38;5;241m=\u001b[39m KMeans(n_clusters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mclusters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumarray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     colors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:1186\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1185\u001b[0m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[0;32m-> 1186\u001b[0m labels, inertia, centers, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43mkmeans_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenters_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;66;03m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;66;03m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[1;32m   1200\u001b[0m \u001b[38;5;66;03m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1203\u001b[0m     inertia \u001b[38;5;241m<\u001b[39m best_inertia\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters)\n\u001b[1;32m   1205\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/sklearn/cluster/_kmeans.py:539\u001b[0m, in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, sample_weight, centers_init, max_iter, verbose, x_squared_norms, tol, n_threads)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict_convergence:\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;66;03m# rerun E-step so that predicted labels match cluster centers\u001b[39;00m\n\u001b[1;32m    523\u001b[0m     elkan_iter(\n\u001b[1;32m    524\u001b[0m         X,\n\u001b[1;32m    525\u001b[0m         sample_weight,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m         update_centers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    537\u001b[0m     )\n\u001b[0;32m--> 539\u001b[0m inertia \u001b[38;5;241m=\u001b[39m \u001b[43m_inertia\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels, inertia, centers, i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "from PIL.ExifTags import TAGS\n",
    "from matplotlib import widgets\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import webcolors\n",
    "import progressbar\n",
    "\n",
    "\n",
    "def main_colors(imgfile):\n",
    "    numarray = np.array(imgfile.getdata(), np.uint8)\n",
    "    if len(numarray.shape) == 2:\n",
    "        clusters = KMeans(n_clusters = 2)\n",
    "        clusters.fit(numarray)\n",
    "        colors = []\n",
    "        for i in range(2):\n",
    "            color = '#%02x%02x%02x' % (\n",
    "                math.ceil(clusters.cluster_centers_[i][0]),\n",
    "                    math.ceil(clusters.cluster_centers_[i][1]), \n",
    "                math.ceil(clusters.cluster_centers_[i][2]))\n",
    "            colors.append(color)\n",
    "        return colors\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "def get_closest_color(rgb_triplet):\n",
    "    min_colours = {}\n",
    "    for key, name in webcolors.CSS21_HEX_TO_NAMES.items():\n",
    "        r_c, g_c, b_c = webcolors.hex_to_rgb(key)\n",
    "        rd = (r_c - rgb_triplet[0]) ** 2\n",
    "        gd = (g_c - rgb_triplet[1]) ** 2\n",
    "        bd = (b_c - rgb_triplet[2]) ** 2\n",
    "        min_colours[(rd + gd + bd)] = name\n",
    "    return min_colours[min(min_colours.keys())]\n",
    "\n",
    "df = pd.read_csv('images/pokemon.csv', sep=',',header=None, skiprows=1)\n",
    "df.replace(np.nan, \"\")\n",
    "json_data = []\n",
    "id = 0\n",
    "total = len([name for name in os.listdir(\"images/images/\")])\n",
    "bar = progressbar.ProgressBar(widgets=['Extraction : ', ' ',progressbar.Percentage(), progressbar.Bar(marker='#',left='[',right=']'),\n",
    "           ' '], maxval=total)\n",
    "bar.start()\n",
    "\n",
    "for filename in os.listdir(\"images/images/\")[:number_of_image_to_extract]:\n",
    "    f = \"images/images/\" + filename\n",
    "    image = Image.open(f)\n",
    "    image = image.resize((120,120))\n",
    "    metadata = df.loc[df[0] == filename.split(\".\")[0]]\n",
    "  \n",
    "    closest_name_list = []\n",
    "    name = metadata[0].values[0]\n",
    "    main_colors_value = main_colors(image)\n",
    "    for i in range(len(main_colors_value)):\n",
    "        rgb_color = ImageColor.getcolor(main_colors_value[i], \"RGB\")\n",
    "        closest_name = get_closest_color(rgb_color)\n",
    "        closest_name_list.append(closest_name)  \n",
    "\n",
    "    id+=1\n",
    "    json_metadata = {\n",
    "        \"id\" : id,\n",
    "        \"properties\" : {\n",
    "            \"name\" : metadata[0].replace(np.nan, \"None\").values[0],\n",
    "            \"type1\" : metadata[1].replace(np.nan, \"None\").values[0],\n",
    "            \"type2\" : metadata[2].replace(np.nan, \"None\").values[0]\n",
    "        },\n",
    "        \"size\" : image.size,\n",
    "        \"colors\" : main_colors_value,\n",
    "        \"closest_colors\": closest_name_list,\n",
    "        \"tags\" : [],\n",
    "        \"path\" : f \n",
    "    }\n",
    "    bar.update(id)\n",
    "    json_data.append(json_metadata)\n",
    "bar.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write metadata to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"images/metadata/metadata.json\", 'w+') as outfile:\n",
    "    outfile.write(json.dumps(json_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 count unique       top freq\n",
      "properties.type1                            \n",
      "Bug                 23      1       Bug   23\n",
      "Dark                 4      1      Dark    4\n",
      "Dragon               5      1    Dragon    5\n",
      "Electric            11      1  Electric   11\n",
      "Fairy                5      1     Fairy    5\n",
      "Fighting             7      1  Fighting    7\n",
      "Fire                13      1      Fire   13\n",
      "Ghost                5      1     Ghost    5\n",
      "Grass               19      1     Grass   19\n",
      "Ground               9      1    Ground    9\n",
      "Ice                  9      1       Ice    9\n",
      "Normal              25      1    Normal   25\n",
      "Poison              12      1    Poison   12\n",
      "Psychic             10      1   Psychic   10\n",
      "Rock                10      1      Rock   10\n",
      "Steel                9      1     Steel    9\n",
      "Water               24      1     Water   24\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import squarify\n",
    "with open('images/metadata/metadata.json','r') as f:\n",
    "    data = json.loads(f.read())\n",
    "    dataFrame = pd.DataFrame(data)\n",
    "\n",
    "df = pd.read_json('images/metadata/metadata.json')\n",
    "\n",
    "df = pd.json_normalize(\n",
    "    data,  \n",
    "    meta=[\n",
    "        'class',\n",
    "        ['properties', 'type1', 'types2'],\n",
    "        'colors' \n",
    "    ]\n",
    ")\n",
    "\n",
    "## Count by type\n",
    "grouped_df = df.groupby(['properties.type1'])['properties.type1']\n",
    "print(grouped_df.describe())\n",
    "x = []\n",
    "y = []\n",
    "for key, item in grouped_df:\n",
    "    group = grouped_df.get_group(key)\n",
    "    x.append(key)\n",
    "    y.append(group.count())\n",
    "\n",
    "plt.bar(x,y )\n",
    "plt.show()\n",
    "\n",
    "### Colors bar \n",
    "count_by_colors = {}\n",
    "\n",
    "for el in data:\n",
    "    colors = el[\"closest_colors\"]\n",
    "    for color in colors:\n",
    "        if color in count_by_colors.keys():\n",
    "            count_by_colors[color] += 1\n",
    "        else: \n",
    "            count_by_colors[color] = 1\n",
    "\n",
    "plt.bar(range(len(count_by_colors)), list(count_by_colors.values()), align='center', color=count_by_colors.keys())\n",
    "plt.xticks(range(len(count_by_colors)), list(count_by_colors.keys()))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'presence':count_by_colors.values(), 'color':count_by_colors.keys() })\n",
    "\n",
    "# plot it\n",
    "squarify.plot(sizes=df['presence'], label=df['color'], alpha=.8 ,color=count_by_colors.keys())\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "_, axs = plt.subplots(2, 5, figsize=(8, 8))\n",
    "axs = axs.flatten()\n",
    "for ax in axs:\n",
    "    image = list(dataFrame.sample()['path'].items())[0][1]\n",
    "    img = mpimg.imread(image)\n",
    "    ax.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate random users preferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of user to generate preferences :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_users = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(\"images/metadata/metadata.json\", 'r') as images_infos:\n",
    "    images_infos = json.load(images_infos)\n",
    "users_preferences = []\n",
    "number_of_user = 10 \n",
    "for user_id in range(number_of_users):\n",
    "    favorites_index = random.sample(range(1,len(images_infos)), 8)\n",
    "    dislike_index = random.choices([i for i in range(1, len(images_infos)) if i not in favorites_index], k=8)\n",
    "\n",
    "    favorites_colors = [images_infos[index][\"closest_colors\"] for index in favorites_index if len(images_infos[index][\"closest_colors\"])]\n",
    "\n",
    "    favorites_types = [[images_infos[index][\"properties\"][\"type1\"], images_infos[index][\"properties\"][\"type2\"]] for index in favorites_index]\n",
    "    disliked_types = [[images_infos[index][\"properties\"][\"type1\"], images_infos[index][\"properties\"][\"type2\"]] for index in dislike_index]\n",
    "    user_metadata = {\n",
    "        \"id\" : user_id +1,\n",
    "        \"favorites\" : favorites_index,\n",
    "        \"dislikes\" : dislike_index,\n",
    "        \"favorites_types\" : list(set(tuple(el) for el in favorites_types)),\n",
    "        \"disliked_types\" : list(set(tuple(el) for el in disliked_types)),\n",
    "        \"colors\" : list(set(np.array(favorites_colors).ravel()))\n",
    "    }\n",
    "    users_preferences.append(user_metadata)\n",
    "with open(\"images/metadata/users_preferences.json\", 'w+') as outfile:\n",
    "    outfile.write(json.dumps(users_preferences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image recommandation based on user preferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "with open('images/metadata/metadata.json') as meta:\n",
    "    meta_data = json.load(meta)\n",
    "    colors_closet1 = [val['closest_colors'][0] if len(val['closest_colors']) > 1 else None for val in meta_data]\n",
    "    colors_closet2 = [val['closest_colors'][1] if len(val['closest_colors']) > 1 else None for val in meta_data]\n",
    "\n",
    "    colors1 = [val['colors'][0] if len(val['colors']) > 1 else None for val in meta_data]\n",
    "    colors2 = [val['colors'][1] if len(val['colors']) > 1 else None for val in meta_data]\n",
    "\n",
    "    df_images = pd.json_normalize(\n",
    "    meta_data,  \n",
    "        meta=[\n",
    "            'class',\n",
    "            ['properties', 'type1', 'types2'], \n",
    "        ]\n",
    "    )   \n",
    "    df_test = pd.json_normalize(\n",
    "    meta_data,  \n",
    "        meta=[\n",
    "            'class',\n",
    "            ['properties', 'type1', 'types2'], \n",
    "        ]\n",
    "    )   \n",
    "    df_images = df_images[df_images.columns[~df_images.columns.isin(['size', 'id','properties.name', 'tags', 'path', 'colors', 'closest_colors'])]]\n",
    "    df_images['colors1'] = colors1\n",
    "    df_images['colors2'] = colors2\n",
    "    df_images['colors_closet1'] = colors_closet1\n",
    "    df_images['colors_closet2'] = colors_closet2\n",
    "\n",
    "with open('images/metadata/users_preferences.json') as user_metadata:\n",
    "    user_data = json.load(user_metadata)\n",
    "    df_u = pd.json_normalize(user_data)\n",
    "\n",
    "le1 = LabelEncoder()\n",
    "df_images['colors1'] = le1.fit_transform(df_images['colors1'])\n",
    "df_images['colors2'] = le1.fit_transform(df_images['colors2'])\n",
    "\n",
    "le2 = LabelEncoder()\n",
    "df_images['colors_closet1'] = le2.fit_transform(df_images['colors_closet1'])\n",
    "df_images['colors_closet2'] = le2.fit_transform(df_images['colors_closet2'])\n",
    "\n",
    "le3 = LabelEncoder()\n",
    "df_images['properties.type2'] = le3.fit_transform(df_images['properties.type2'])\n",
    "df_images['properties.type1'] = le3.fit_transform(df_images['properties.type1'])\n",
    "\n",
    "\n",
    "\"\"\"Separate data for train set and test set\"\"\"\n",
    "train = df_images[:650]\n",
    "test = df_images[650:]\n",
    "\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "\n",
    "fitted_models = []\n",
    "\n",
    "def randomDf():\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(8):\n",
    "        df = pd.concat([df, train.sample()], ignore_index = True, axis = 0)\n",
    "    return df\n",
    "\n",
    "label_likes = LabelEncoder()\n",
    "users_preferences = {}\n",
    "for index, row in df_u.iterrows():\n",
    "    fits = dtc.fit(randomDf(), label_likes.fit_transform(row['favorites']))\n",
    "    prediction = fits.predict(test)\n",
    "    users_preferences[index] = df_test.iloc[label_likes.inverse_transform(prediction.reshape(-1, 1))]\n",
    "\n",
    "\n",
    "users_ids = []\n",
    "def users_images():\n",
    "    for index in range(8):\n",
    "        # ax.set_title(f\"User {index} and image favorites id :{list(users_preferences[index].sample()['id'].items())[0][1]}\")\n",
    "        random_favorite = np.random.choice(df_u.iloc[index]['favorites'], size=1)\n",
    "        favorite = random_favorite.tolist().pop(0)\n",
    "        recommanded =  list(users_preferences[index].sample()['id']).pop(0)\n",
    "        users_ids.append(favorite)\n",
    "        users_ids.append(recommanded)\n",
    "\n",
    "users_images()\n",
    "\n",
    "fig , axs = plt.subplots(8,2, figsize=(8, 8))\n",
    "fig.suptitle(\"Each row is a user and left image is favorite and right is a recommanded\")\n",
    "axs = axs.flatten()\n",
    "def plot_users(plot):\n",
    "    for index, ax in enumerate(plot):\n",
    "        ax.set_title(f\"Image number : {users_ids[index]}\")\n",
    "        img = mpimg.imread(df_test.iloc[users_ids[index]]['path'])\n",
    "        ax.imshow(img)\n",
    "    plt.show()\n",
    "plot_users(axs)\n",
    "\n",
    "for i in range(8):\n",
    "    print(\"User number :\",i,\" with a random recommanded image : \\n\")\n",
    "    print(users_preferences[i].sample())\n",
    "    print('\\nFavorites types, color and image for this user : \\n')\n",
    "    print(df_u.iloc[i]['favorites_types'])\n",
    "    print(df_u.iloc[i]['colors'])\n",
    "    print(df_u.iloc[i]['favorites'])\n",
    "    print('\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
